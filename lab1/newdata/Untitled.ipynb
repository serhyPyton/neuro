{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(object):\n",
    "    def __init__(self, weights_vector, learning_rate, dimension = 2): #function of initialization\n",
    "        self.weights = weights_vector #it takes 4 arguments\n",
    "        self.rate = learning_rate     #weights_vector is what we are looking for\n",
    "        self.output = 0               #learning_rate shows the number of performed improvemenet for the next cycle\n",
    "        self.data = self.read_data()  #output is what we have as the result\n",
    "        self.dimension = dimension    #dimension shows the length of input vector\n",
    "                                      #here the dimension =2, 'cause x=(x_0,x_1)\n",
    "    @staticmethod                       #returns static function\n",
    "    def read_data(name = \"data01.csv\"): #reading process of our data, here it is .csv for 7th variant\n",
    "        df = pd.read_csv(name,  names = [\"x0\", \"x1\", \"d\"], sep = ';' )\n",
    "        #reading of 3 columns\n",
    "        return df\n",
    "    \n",
    "    def learning_process(self):\n",
    "        a = 200                                               #number of learning cycles\n",
    "        while (a):\n",
    "            previous_weights = self.weights\n",
    "            column = self.random_column()\n",
    "            #choosing the random column and dealing with it\n",
    "            u = np.dot(self.weights, column[:self.dimension]) #scalar multiplication of weights and input values \n",
    "            self.step(u)                                      #without including of d\n",
    "            for i in range(0,self.dimension):\n",
    "                self.weights[i] = previous_weights[i] + self.rate * (column[self.dimension] - self.output)*column[i]\n",
    "            #formula for improving the values of weights (w_i(t+1)=w_i(t)+a*(d-out)*in_i)\n",
    "            a-=1\n",
    "        return self.weights\n",
    "    \n",
    "    def random_column(self):\n",
    "        t = random.randint(0,99)    #the range for random values\n",
    "        return list((self.data.ix[t]))\n",
    "    \n",
    "    def step(self, u):      #step-function. output of which is either 0 or 1\n",
    "        if u >= 0.5:        #depending on the value of u\n",
    "            self.output = 1 #classicaly this value is compared with 0\n",
    "        else:               #but it can be any other number\n",
    "            self.output = 0 #here it is 0.5\n",
    "            \n",
    "    def test(self):\n",
    "        a = 100     #testing 100 columns and weights\n",
    "        num = 0\n",
    "        while(a):\n",
    "            column = self.random_column()\n",
    "            u = np.dot(self.weights, column[:self.dimension]) #scalar multiplication of weights and input values\n",
    "            self.step(u)\n",
    "            if self.output == column[self.dimension]:\n",
    "                num+=1      #counting right outputs\n",
    "            a-=1\n",
    "        return num          #percent of right outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_learning():\n",
    "    \n",
    "    t = []\n",
    "    r = []\n",
    "    for i in range(0,10):       #the number of test cycles\n",
    "        neuron = Perceptron(weights_vector=[0.5, -0.5], learning_rate=0.1) #initial definition of weights and learning value (from 0 to 1)\n",
    "        neuron.learning_process()\n",
    "        t.append(neuron.test()) #adding more objects to the t-array\n",
    "        r.append(neuron.learning_process())\n",
    "    mn = np.mean(t)             #average t-value\n",
    "    print(\"Your precision on 10 learning iterations with 200 epochs in each learning is {}% \".format(mn))\n",
    "    print(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/site-packages/ipykernel_launcher.py:31: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your precision on 10 learning iterations with 200 epochs in each learning is 95.1% \n",
      "[[0.9841000000000006, 0.047199999999999964], [0.985, 0.02549999999999995], [0.966, 0.04770000000000003], [0.9382000000000001, 0.13190000000000002], [0.9737000000000002, 0.04149999999999997], [0.9521000000000004, 0.006099999999999987], [0.9200000000000004, 0.13640000000000002], [1.0190000000000001, 0.04550000000000002], [1.0246000000000004, 0.014100000000000053], [0.9379, 0.07930000000000008]]\n"
     ]
    }
   ],
   "source": [
    "test_learning()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
